---
title: "Fitting a spatiotemporal model and deriving an abundance index"
date: "`r format(Sys.Date(), format='%B %d %Y') `"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Fitting a spatiotemporal model and deriving an abundance index}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, message=FALSE, error=FALSE, warning = FALSE, 
  comment = "#>", 
  eval = FALSE
)
```

> Adapted from Lewis Barnett's sdmTMB tutorial for the Fisheries Survey Course at UW: [GitHub pbs-assess/sdmTMB-teaching 2023-02-14](https://github.com/pbs-assess/sdmTMB-teaching/blob/490ee04157f19d1059c55a1318b894e8b8f460bb/uw-survey-2023/02-exercise.qmd#L356)

# Goals of the original exercise:

-   Practice fitting a basic spatiotemporal model.
-   Understand how to inspect the model output.
-   Practice predicting from the model on new data and making visualizations of those predictions.
-   Gain familiarity with fitting, comparing and interpreting different random field structures.
-   Calculate an area-weighted biomass index and compare how model structure can impact an index.

# Our goals for this vignette:

- Fit a GAM and obtain an area-weighted biomass index
- Fit a basic spatiotemporal model (a GLMM!) using sdmTMB and compare GAM to GLMM 

```{r install_inla, eval = FALSE, include = FALSE}
# install.packages("INLA", repos = c(getOption("repos"), INLA = "https://inla.r-inla-download.org/R/stable"), dependencies = TRUE)
#library(remotes)
#remotes::install_github("pbs-assess/sdmTMB", dependencies = TRUE)
```

```{r}
PKG <- c(
  "sdmTMB", # install.packages("sdmTMB", dependencies = TRUE)
  "mgcv", 
  "gratia",
  "visreg", 
  "gstat",
  "dplyr", 
  "ggplot2", 
  "INLA",
  "prediction",
  "inlabru", 
  "purrr")

for (p in PKG) {
  if(!require(p,character.only = TRUE)) {  
    install.packages(p)
    require(p,character.only = TRUE)}
}

options(ggplot2.continuous.colour = "viridis")
options(ggplot2.continuous.fill = "viridis")
theme_set(theme_light())
```

Check your system:

```{r}
sessionInfo()
```

# The data

We will work with data representing North Pacific Spiny Dogfish in the West Coast Vancouver Island synoptic trawl survey.

```{r, include = FALSE}
# https://drive.google.com/drive/folders/14h9nrWR_eoSlmfFI0KXfotEIJHyVJzHQ
#dat <- readRDS(here::here("notforgit/uw-survey-2023/data/wcvi-dogfish.rds"))
#head(dat)

dat <- readRDS(here::here("data/ebs_yfs_example.RDS"))

#load(here::here("data/noaa_afsc_public_foss.rda"))
#yfs <- noaa_afsc_public_foss %>% filter(srvy=="EBS" & species_code == 10210 )
#saveRDS(object = yfs,file = here::here("data/ebs_yfs_example.RDS"))
```

The dataset contains sampling locations (`longitude` and `latitude`) and `year`. It also contains sampling `depth` in meters and sample CPUE `density` in units of tonnes/km^2^.

```{r}
ggplot(data = dat, 
       mapping = aes(x = longitude_dd, y = latitude_dd, size = count, color = bottom_temperature_c)) + 
  geom_point(alpha = 0.3)
```



# Fit a GAM to spatial data (analogous to spatial-only model in sdmTMB)

## Add UTM columns, log depth, and year as factor
```{r}
dat <- add_utm_columns(dat, 
                       ll_crs = 4326,
                       ll_names = c("longitude_dd", "latitude_dd"))

dat$log_depth <- log(dat$depth_m)
dat$year_factor <- as.factor(dat$year)

dat[,c("X","Y")]

ggplot(dat, aes(X, Y, size = cpue_kgkm2)) +
  geom_point(shape = 21) +
  coord_fixed()
```

First, fit a GAM without any covariates: just year as a factor and a spatial smoother $s(X,Y)$.
```{r}
start.time <- Sys.time()
fit_gam <- gam(
  formula = count ~ as.factor(year) + 
    s(X, Y), 
  family = tw(link = "log"),
  #offset = "area_swept_ha", # only for when modeling cpue
  data = dat
)

cat("The GAM took ", Sys.time() - start.time, " seconds to run")
```

Include a 2-D smooth over space. The `as.factor(year)` part is a common component of SDMs that are being used to generate indices.

```{r}
start.time <- Sys.time()
fit_gam_s <- gam(
  formula = count ~ s(depth_m) + as.factor(year) + 
    s(X,Y), 
  family = tw(link = "log"),
  #offset = "area_swept_ha", # only for when modeling cpue
  data = dat
)

cat("The GAM took ", Sys.time() - start.time, " seconds to run")
```


# Fit a GAM analogous to a spatiotemporal model in sdmTMB

Include a 2-D smooth over space for each year

```{r}
start.time <- Sys.time()

fit_gam_st <- gam(
  formula = count ~ s(depth_m) + as.factor(year) +
    s(X,Y, by = year), 
  family = tw(link = "log"),
 # offset = "area_swept_ha",
  data = dat)

cat("The GAM took ", Sys.time() - start.time, " seconds to run")
```


Get diagnostics and perform model checking

```{r}
gam.check(fit_gam_st)
```

Review console output to help verify convergence, and whether there were an adequate number of basis functions (k).

Examine the four diagnostic plots. Each of these gives a different way of looking at your model residuals. On the top-left is a Q-Q plot, which compares the model residuals to the expected/assumed distribution family. A well-fit model's residuals will be close to the 1-1 line, otherwise there may be under- or over-dispersion present. On bottom left is a histogram of residuals. We want this to have a shape similar to the distribution family we specified. On top-right is a plot of residual values as a function of the linear predictor. These should be evenly distributed around zero in a well-fitted model. Finally, on the bottom-right is plot of response against fitted values. A well-fitted model would show values near the 1-1 line.

# Predict to survey area (new data)

## Load the grid
Extrapolation grid for the EBS. 

```{r}
#load(here::here("data/pred_grid_ebs.rda")) # object: pred_grid_ebs
# try this new grid
#pred_grid_ebs <- read.csv(here::here("data/ebs_2022_epsg3338.csv"),header = TRUE)

get_crs(dat = pred_grid_ebs,ll_names =c("lon","lat"))

grid <- add_utm_columns(pred_grid_ebs, 
                       #ll_crs = 32603, 
                       ll_names = c("lon", "lat"))
range(grid$X)

# Bunch of annoying stuff here, still doesn't work
#crs_utm <- 32603  # # Zone 3 UTM CRS - grabbed from prey habitat project
# grid <- sf::st_as_sf(pred_grid_ebs, coords=c("lon","lat"),crs="EPSG:4326") |>
#   sf::st_transform(crs = crs_utm) 

#wcvi_grid <- readRDS(here::here("data/wcvi-grid.rds"))

```

When you have spatiotemporal data, you need a grid for each year. There is a nice tidy little chunk of `{purrr}` code that will do that for you!

```{r}
grid <- purrr::map_dfr(unique(dat$year), ~ tibble(grid, year = .x))
```


## Predict CPUE across the grid

```{r}
pred_gam <- predict(fit_gam, type = "response", newdata = grid)
pred_gam_df <- cbind(grid, pred_gam) #Careful! This takes a long time.
```

Plot predictions over survey area. Note: I Keep getting geom_raster errors in this part; not sure what's happening.

```{r}
pred_gam_df %>%
  filter(year==1999) |>
ggplot(aes(X, Y, color=pred_gam)) + 
  geom_point() + # Sean uses geom_tile or geom_stars if it's a stars object
  scale_fill_viridis_c() + 
  #facet_wrap(~year) + 
  coord_fixed() +
  labs(fill = "Log Biomass density\n(kg/km^2)")
```

# Index standardization

To calculate an index from any of these models, we need to run the `predict.sdmTMB()` function with the argument `return_tmb_object = TRUE`. We can then run the `get_index()` function to extract the total biomass calculations and standard errors.

We can set the area argument to our `cell_area` column in km^2^. In this case the value is 4 km^2^ for all of the cells, since our grid cells are 2 km x 2 km. If some grid cells were not fully in the survey domain (or were on land), we could feed a vector of grid areas to the area argument that matched the number of grid cells. Because the density units are tonnes per km^2^ for this data, the index is in tonnes.

```{r}
p <- predict(fit, newdata = grid, return_tmb_object = TRUE)
index <- get_index(p, area = grid$cell_area, bias_correct = FALSE)

ggplot(index, aes(year, est)) +
  geom_line() +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.4) +
  xlab("Year") +
  ylab("Biomass estimate (tonnes)")
```

We used `bias_correction = FALSE` to speed things up, but for any final result you will want to use the bias correction. Let's see how much the scale of the index changes with bias correction.

```{r}
index_c <- get_index(p, area = grid$cell_area, bias_correct = TRUE)
index_c$Method <- "Bias correction"

bind_rows(index, index_c) %>%
  ggplot(aes(year, est, fill = Method)) +
  geom_line(aes(colour = Method)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.4) +
  xlab("Year") +
  ylab("Biomass estimate (tonnes)")
```


# Calculate biomass index from GAM via simulation

```{r}
sims <- gratia::fitted_samples(fit_gam, n=10, newdata=grid, 
                               scale="response", seed=9)
sims$year <- grid$year[sims$row]
sims$biomass <- sims$fitted * 4 # expand from density to biomass, given area

level <- 0.95 # specify probability for confidence interval

# Get sum of simulated biomass (density*area) across grid cells, with CI
lwr_fn <- function(x) {as.numeric(quantile(x, probs = (1 - level) / 2))}
upr_fn <- function(x) {as.numeric(quantile(x, probs = 1 - (1 - level) / 2))}

sims_sum <-  sims %>% 
  group_by(year,draw) %>% 
  summarise_at("biomass", list(biomass = sum)) %>%
  group_by(year) %>%
  summarise_at("biomass", list(est = median, # could use mean
                           lwr = lwr_fn,
                           upr = upr_fn))
```

Note that this approach uses a Gaussian approximation to the posterior, which is all that is implemented currently in the gratia package. However, a better estimate of uncertainty could be derived from sampling from the actual posterior distribution. However, this is beyond the scope of today's lesson.

Plot the biomass index:

```{r}
ggplot(sims_sum, aes(year, est)) + geom_line() +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.4) +
  xlab('Year') + ylab('Biomass estimate (kg)')
```
