---
title: "{sdmgamindex} case study with and without covariates"
date: "`r format(Sys.Date(), format='%B %d %Y') `"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{{sdmgamindex} case study with and without covariates}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, message=FALSE, error=FALSE, warning = FALSE, 
  comment = "#>"
)

# library(remotes)
PKG <- c(
  "sdmgamindex", 
  "DATRAS", # remotes::install_github("DTUAqua/DATRAS/DATRAS")
  "dplyr",
  "sf", 
  "gstat",
  "magrittr", 
  "flextable", 
  "raster", 
  "dplyr", 
  "magrittr",
  
  # RACE-GAP Specific R packages
  "akgfmaps", # devtools::install_github("afsc-gap-products/akgfmaps", build_vignettes = TRUE)
  "coldpool" # devtools::install_github("afsc-gap-products/coldpool")
)

for (p in PKG) {
  # if(!require(p,character.only = TRUE)) {  
    # install.packages(p)
    require(p,character.only = TRUE)}
# }
```

## Case study

In this example, we will use data from NOAA Fisheries' eastern Bering sea (EBS) bottom trawl survey. The Resource Assessment and Conservation Engineering (RACE) Division Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC) conducts fisheries-independent bottom trawl surveys to assess the populations of demersal fish and crab stocks of Alaska. The species covered in this case study include yellow fin sole, walleye pollock, and red king crab. 

```{r info-table, eval = TRUE, echo = FALSE}
img_url <- paste0("https://raw.githubusercontent.com/afsc-gap-products/gap_bs_data_report/main/img/", 
                  c("yellowfin-sole", "walleye-pollock", "red-king-crab"), ".png")
img_loc <- here::here("vignettes", paste0(c("yellowfin-sole", "walleye-pollock", "red-king-crab"), ".png")) 
for (i in 1:length(img_loc)) {download.file(url = img_url[i], destfile = img_loc[i], mode="wb")}

table_raw <- data.frame(img = img_loc, 
                        Species = c("Yellowfin Sole", "Walleye pollock", "Red King Crab"), 
                        Description = 
                          c("Commonly caught species has been realitively easy to model and assess because of it's high abundance, large distribution over the survey area, and consistent availability to the survey.", 
                            "Common to the survey, but their distribution and availability to the survey are driven by density-dependence and temperature and the cold pool extent. Including covariates in model fits could help uncover structure that could help us better understand this specie's abundance.", 
                            "Has patchier and less understood availability to the survey. "))

table_print <- table_raw %>% 
  flextable::flextable(
    col_keys = c("img", "dummy")) %>%
  flextable::compose(j = "dummy", part = "body",
                     value = as_paragraph(
                       as_chunk(paste0(Species, "\n"),
                                props = fp_text_default(bold = TRUE, font.size = 12)), 
                       as_chunk(Description,
                                props = fp_text_default(font.size = 10)))) %>%  
  flextable::colformat_image(j = "img", 
                             height = 2, 
                             width = 2) %>% 
  flextable::delete_part(x = ., part = "header") %>% 
  flextable::border_remove(x = .) %>% 
  flextable::autofit()

table_print
```

And we are going to estimate the indicies of these species Over the eastern and northern Bering Sea shelf. 

```{r survey-figure, echo=FALSE, fig.cap=readLines("https://raw.githubusercontent.com/afsc-gap-products/survey-live-temperature-map/main/examples/current_grid_bs.txt"), out.width = '100%'}

img_url <- "https://raw.githubusercontent.com/afsc-gap-products/survey-live-temperature-map/main/examples/current_grid_bs.png"
img_loc <- here::here("vignettes", "current_grid_bs.png")
download.file(url = img_url, destfile = img_loc, mode="wb")
knitr::include_graphics(img_loc)
```

For the sake of a simple example, we will only assess data from 2015 to 2021. 

```{r vars} 
SPECIES <- c("yellowfin sole", "walleye pollock", "red king crab")
YEARS <- 2015:2023
SRVY <- "EBS"
```

## 1. What data area we using?

Here, we use the public facing data from the [NOAA AFSC groundfish Bering sea bottom trawl survey](https://www.fisheries.noaa.gov/foss). For more information about how these data were compiled, see [afsc-gap-products GitHub repo](https://afsc-gap-products.github.io/gap_products/content/foss-intro.html). 

```{r view-data}
dat <- sdmgamindex::noaa_afsc_public_foss %>% 
  dplyr::filter(srvy == SRVY &
                  year %in% YEARS &
                  common_name %in% SPECIES) %>%
  dplyr::mutate(hauljoin = paste0(stratum, "_", station, "_", date_time)) %>%
  dplyr::select(
    year, date_time, latitude_dd_start, longitude_dd_start, # spatiotemproal data
    cpue_kgkm2, common_name, # catch data
    bottom_temperature_c, depth_m, # possible covariate data
    srvy, area_swept_km2, duration_hr, vessel_id, hauljoin # haul/effort data)
  )
```

```{r view-data-show}
table(dat$common_name)
head(dat)
```

## 2. Prepare the data from sdmgamindex::get_surveyidx():

```{r data-wrangle}
# project spatial data
crs_proj <- "EPSG:3338" # NAD83 / Alaska Albers
crs_latlon <- "+proj=longlat +datum=WGS84" # decimal degrees

ll <- sdmgamindex::convert_crs( 
  x = dat$longitude_dd_start,
  y = dat$latitude_dd_start, 
  crs_in = crs_latlon, 
  crs_out = crs_proj) 

YEARS <- sort(unique(dat$year))

# The sdmgamindex::get_surveyidx() expects some columns to be named in a specific way
dat_wrangled <- dat %>% 
  dplyr::rename(
    Year = year,
    wCPUE = cpue_kgkm2, 
    COMMON_NAME = common_name,
    GEAR_TEMPERATURE = bottom_temperature_c, 
    BOTTOM_DEPTH = depth_m,
    HaulDur = duration_hr,
    EFFORT = area_swept_km2,
    Ship = vessel_id) %>%
  dplyr::mutate( 
    # create some other vars
    Lon = longitude_dd_start, 
    Lat = latitude_dd_start, 
    lon = ll$X,
    lat = ll$Y,
    sx = ((longitude_dd_start - mean(longitude_dd_start, na.rm = TRUE))/1000),
    sy = ((latitude_dd_start - mean(latitude_dd_start, na.rm = TRUE))/1000), 
    ctime = as.numeric(as.character(Year)),
    date_time = as.Date(x = date_time, format = "%m/%d/%Y %H:%M:%S"), 
    hour = as.numeric(format(date_time,"%H")),
    minute = as.numeric(format(date_time,"%M")),
    day = as.numeric(format(date_time,"%d")),
    month = as.numeric(format(date_time,"%m")),
    TimeShotHour = hour + minute/60,
    timeOfYear = (month - 1) * 1/12 + (day - 1)/365,   
    
    # add some dummy vars and create some other vars
    Country = "USA",
    Gear = "dummy",
    Quarter = "2")  %>%
  dplyr::mutate(across((c("Year", "Ship", "COMMON_NAME")), as.factor)) %>% 
  dplyr::select(wCPUE, GEAR_TEMPERATURE, BOTTOM_DEPTH, COMMON_NAME, EFFORT, 
                Year, Ship, Lon, Lat, lat, lon, sx, sy, 
                ctime, TimeShotHour, timeOfYear, Gear, Quarter, HaulDur, hauljoin)
```

```{r data-wrangle-show}
head(dat_wrangled)
```

## 3. Define representitive station points to fit and predict the model at

Since surveys are not done at the same *exact* location each year (it's the intention, but impossible in practice), we need to define what representative latitudes and longitudes we are going to predict at. 

These are the same prediction grids AFSC uses for their 2021 [VAST model-based indices](https://github.com/James-Thorson-NOAA/VAST) (which is subject to change - do not use this without asking/checking that this is still current!). 

```{r prediction-grid}
pred_grid <- sdmgamindex::pred_grid_ebs

ll <- sdmgamindex::convert_crs( 
  x = pred_grid$lon,
  y = pred_grid$lat, 
  crs_in = crs_latlon, 
  crs_out = crs_proj) 

pred_grid <- pred_grid %>% 
  dplyr::mutate( 
    lon = ll$X,
    lat = ll$Y,
    sx = ((lon - mean(lon, na.rm = TRUE))/1000),
    sy = ((lat - mean(lat, na.rm = TRUE))/1000))
```

```{r prediction-grid-show}
head(pred_grid)
```

It is also good to have a shapefile on hand to crop and constrain your outputs too. Here at AFSC GAP, we have developed the [{akgfmaps} R package](https://github.com/afsc-gap-products/akgfmaps) to save and share such shapefiles. 

```{r survey-shapefile}
# library(devtools)
# devtools::install_github("afsc-gap-products/akgfmaps", build_vignettes = TRUE)
library(akgfmaps)

map_layers <- akgfmaps::get_base_layers(
  select.region = "bs.south",
  set.crs = crs_proj)

# Let's just see what that looks like:
tmp <- map_layers$survey.area
tmp$AREA_KM2 <- tmp$PERIM_KM <- NULL
```

```{r survey-shapefile-show}
plot(tmp)
```

## 4. Prepare covariate data

Here we want to match covariate data to the prediction grid. 

```{r dat-cov}
dat_cov <- sdmgamindex::pred_grid_ebs %>% 
  dplyr::select(-Shape_Area) %>% 
  dplyr::mutate( 
    sx = ((lon - mean(lon, na.rm = TRUE))/1000),
    sy = ((lat - mean(lat, na.rm = TRUE))/1000))

sp_extrap_raster <- SpatialPoints(
  coords = coordinates(as.matrix(dat_cov[,c("lon", "lat")])), 
  proj4string = CRS(crs_latlon) )
```

```{r dat-cov-show}
dat_cov
sp_extrap_raster
```

### 4a. Data that varies over only space (depth)

Here in the Bering sea, the depth rarely changes. The modeler may consider making this variable time-varying as well if they are say, in the Gulf of Alaska or the Aleutian Islands where currents and island formation can markedly change depth. 

For this, we are going to create a raster of depth in the Bering sea from the survey data so we can merge that into the dataset at the prediction grid lat/lons. 


```{r covar-depth-load, echo=FALSE}
load(file = system.file(paste0("vigD_bottom_depth_raster_",
                               min(YEARS),"-",max(YEARS), ".rdata"), 
                        package = "sdmgamindex" ) )
```

```{r covar-depth, eval=FALSE}
x <- dat_wrangled %>%
  dplyr::select(Lon, Lat, BOTTOM_DEPTH) %>%
  stats::na.omit()  %>% 
  sf::st_as_sf(x = ., 
               coords = c(x = "Lon", y = "Lat"), 
               crs = sf::st_crs(crs_latlon))

idw_fit <- gstat::gstat(formula = BOTTOM_DEPTH ~ 1,
                        locations = x,
                        nmax = 4)

# stn_predict <- raster::predict(idw_fit, x)

extrap_data0 <- raster::predict(
  idw_fit, sp_extrap_raster) %>%
  # as(sp_extrap_raster, Class = "SpatialPoints")) %>%
  sf::st_as_sf() %>%
  sf::st_transform(crs = crs_latlon)  %>%
  stars::st_rasterize() 

extrap_data <- stars::st_extract(x = extrap_data0,
                                 at = as.matrix(dat_cov[,c("lon", "lat")]))

# to make future runs of this faster:
save(extrap_data0, extrap_data, 
     file = here::here("inst",
                       paste0("vigD_bottom_depth_raster_", 
                              min(YEARS),"-",max(YEARS), ".rdata")))
```

```{r covar-depth-show}
# Just so we can see what we are looking at:
plot(extrap_data0, main = "Interpolated Bottom Depths") 

dat_cov <- cbind.data.frame(dat_cov, 
                            "BOTTOM_DEPTH" = extrap_data$var1.pred) %>%
  stats::na.omit()

head(dat_cov)
```

### 4b. Data that varies over space and time (bottom temperature)

Here, bottom temperature, and thereby the cold pool extent, have been show to drive the distribution of many species. This is especially true for walleye pollock. 

For this we are going to lean on our in-house prepared validated and pre-prepared [{coldpool} R package](https://github.com/afsc-gap-products/coldpool) [@RohanColdPool]. This data interpolates over the whole area of the survey so there are no missing data. 

```{r covar-bt-test}
# Just so we can see what we are looking at:
#plot(terra::unwrap(coldpool::ebs_bottom_temperature)) 
```

```{r covar-bt}
tmp <- which(readr::parse_number(names(terra::unwrap(coldpool::ebs_bottom_temperature))) %in% YEARS)

dat_temperature <- terra::unwrap(coldpool::ebs_bottom_temperature)[[tmp]] %>% 
  terra::extract(y = dat_cov[,c("lon", "lat")] %>% 
                   sf::sf_project(from = "+proj=longlat",
                                  to = "EPSG:3338")) %>% 
  data.frame()
names(dat_temperature) <- paste0("GEAR_TEMPERATURE", YEARS)

dat_cov <- dplyr::bind_cols(dat_cov, dat_temperature) %>% 
  na.omit()
```

```{r covar-bt-show, tab.cap = "Adding bottom temperature covariate data. "}
head(dat_cov)
```

## 5. DATRAS structure

### 5a. Catch Data

```{r catch-haul-fill-0}
# Identify vars that will be used --------------------------------------------
varsbyyr <- unique( # c("GEAR_TEMPERATURE", "cpi")
  gsub(pattern = "[0-9]+", 
       replacement = "", 
       x = names(dat_cov)[grepl(names(dat_cov), 
                                pattern = "[0-9]+")]))

vars <- unique( # c("BOTTOM_DEPTH")
  names(dat_cov)[!grepl(names(dat_cov), 
                        pattern = "[0-9]+")])
vars <- vars[!(vars %in% c("LONG", "LAT", "lon", "lat", "sx", "sy"))]

dat_catch_haul <- dat_wrangled 
head(dat_catch_haul)
```

```{r catch_haul_datras }
allpd <- lapply(YEARS, 
                FUN = sdmgamindex::get_prediction_grid, 
                x = dat_cov, 
                vars = vars, 
                varsbyyr = varsbyyr)
names(allpd) <- as.character(YEARS)
```

```{r catch_haul_datras-show}
head(allpd[1][[1]])
```

### 5b. Covariate Data

```{r cov-datras}
## split data by species, make into DATRASraw + Nage matrix
ds <- split(dat_catch_haul,dat_catch_haul$COMMON_NAME)
ds <- lapply(ds, sdmgamindex::get_datrasraw)
## OBS, response is added here in "Nage" matrix -- use wCPUE
ds <- lapply(ds,function(x) { x[[2]]$Nage <- matrix(x$wCPUE,ncol=1); colnames(x[[2]]$Nage)<-1; x } )
```

```{r cov-datras-show}
ds
```

## 6. Formulas

```{r formulas}
fm <-  list(
  # Null model spatial and temporal with an additional year effect
  "fm_1_s_t_st" = "Year +
    s(sx,sy,bs=c('ts'),k=376) +
    s(sx,sy,bs=c('ts'),k=10,by=Year)",
  
  # Mdoel with simple covariates
  "fm_2_cov" =
    "s(BOTTOM_DEPTH,bs='ts',k=10) +
s(log(GEAR_TEMPERATURE+3),bs='ts',k=10)",
  
  # Mdoel with simple covariates and spatial and temporal with an additional year effect
  "fm_3_s_t_st_cov" =
    "Year +
    s(sx,sy,bs=c('ts'),k=376) +
    s(sx,sy,bs=c('ts'),k=10,by=Year) + 
    s(BOTTOM_DEPTH,bs='ts',k=10) +
s(log(GEAR_TEMPERATURE+3),bs='ts',k=10)"
)
```

## 7. Fit the Model

Here are all of the models we want to try fitting:

```{r model_combos, echo = FALSE}
comb <- tidyr::crossing(
  "SPECIES" = SPECIES, 
  "fm_name" = gsub(pattern = " ", replacement = "_", x = names(fm))) %>% 
  dplyr::left_join(
    x = ., 
    y = data.frame("fm" = gsub(pattern = "\n", replacement = "", 
                               x = unlist(fm), fixed = TRUE), 
                   "fm_name" = gsub(pattern = " ", replacement = "_", 
                                    x = names(fm))), 
    by = "fm_name")
```

```{r model_fit_load, echo = FALSE}
# Would normally save the whole list, but need smaller files 
# to fit example on GitHub
# load(system.file("vigD_model_fits.Rdata", package = "sdmgamindex") )

models0 <- list()
for (i in unique(comb$fm_name)){
  load(system.file(paste0("vigD_model_fits_",i,".Rdata"), 
                   package = "sdmgamindex"), verbose = TRUE)
  models0 <- c(models0, models)
}
models <- models0
```

```{r model_fit, eval = FALSE}
models <- fittimes <- list()

for(i in 1:nrow(comb)){
  cat("Fitting ",comb$SPECIES[i],"\n", comb$fm_name[i], ": ", comb$fm[i], "\n")
  
  temp <- paste0(comb$SPECIES[i], " ", comb$fm_name[i])
  
  fittimes[[ temp ]] <-
    system.time ( models[[ temp ]] <-
                    sdmgamindex::get_surveyidx(
                      x = ds[[ comb$SPECIES[i] ]],
                      ages = 1,
                      myids = NULL,
                      predD = allpd,
                      cutOff = 0,
                      fam = "Tweedie",
                      modelP = comb$fm[i],
                      gamma = 1,
                      control = list(trace = TRUE,
                                     maxit = 20))  )
  
}
```

```{r model_fit_save_butdont, eval = FALSE}
save(models, fittimes, file = here::here("inst","vigD_model_fits.Rdata"))
```

```{r model_fit_save_butdo, eval = FALSE, echo = FALSE}
# Would normally save the whole list (like above), but need smaller files 
# to fit example on GitHub
models0 <- models
for (i in unique(comb$fm_name)){
  models <- models0[grepl(pattern = i, x = names(models0))]
  save(models, fittimes, file = here::here("inst",paste0("vigD_model_fits_",i,".Rdata")))
}
models <- models0
```

``` {r model_aic}
# temp <- sapply(models, `[`, "pModels")
# mods <- sapply(temp, `[`, 1)
# lapply(X = mods, FUN = AIC)

# sdmgamindex::get_surveyidx_aic(x = models)
AIC(models$`red king crab fm_1_s_t_st`$pModels[[1]], 
    models$`red king crab fm_2_cov`$pModels[[1]], 
    models$`red king crab fm_3_s_t_st_cov`$pModels[[1]], 
    models$`walleye pollock fm_1_s_t_st`$pModels[[1]], 
    models$`walleye pollock fm_2_cov`$pModels[[1]], 
    models$`walleye pollock fm_3_s_t_st_cov`$pModels[[1]], 
    models$`yellowfin sole fm_1_s_t_st`$pModels[[1]], 
    models$`yellowfin sole fm_2_cov`$pModels[[1]], 
    models$`yellowfin sole fm_3_s_t_st_cov`$pModels[[1]])

```

```{r model_check1_script, eval = FALSE, echo = TRUE}
lapply(models,function(x) gam.check(x$pModels[[1]]))
```

```{r model_check1_run, eval = FALSE, echo = FALSE}
# 
# Quitting from lines 460-462 [model_check1] (D-simple-case-study.Rmd)
# Error: processing vignette 'D-simple-case-study.Rmd' failed with diagnostics:
# figure margins too large
# --- failed re-building 'D-simple-case-study.Rmd'
# par(mfrow = c(2,2))
a <- lapply(models,function(x) gam.check(x$pModels[[1]]))
png(filename = here::here("inst","vigD_gamcheck.png"),
    width=640,height=480)



gam.check2 <- function(b, 
                       title0 = "GAM Model Results", 
                       type = "deviance"  ## "pearson" & "response" are other valid choices
                       ) {
# https://stackoverflow.com/questions/22275610/how-to-get-only-the-plots-from-gam-check
resid <- residuals(b, type = type)
linpred <- napredict(b$na.action, b$linear.predictors)
observed.y <- napredict(b$na.action, b$y)
# QQ plot - This is produced via qq.gam():
f1 <- qq.gam(b, rep = 0, level = 0.9, type = type, rl.col = 2, 
       rep.col = "gray80")
# Histogram of residuals 
f2 <- hist(resid, xlab = "Residuals", main = "Histogram of residuals")
# Residuals vs linear predictor 
f3 <- plot(linpred, resid, main = "Resids vs. linear pred.", 
     xlab = "linear predictor", ylab = "residuals")
# Observed vs fitted values
f4 <- plot(fitted(b), observed.y, xlab = "Fitted Values", 
     ylab = "Response", main = "Response vs. Fitted Values")
figure <- cowplot::plot_grid(title0, f1, f2, f3, f4, 
                             nrow = 3, rel_heights = c(0.1, 1, 1))
}

gam.check2(b = models[[1]]$pModels, names(models[1]))
```

```{r model_check1_show, eval = TRUE, echo = FALSE}
```

```{r model_check2}
## Model summaries
lapply(models,function(x) summary(x$pModels[[1]]))
```

## 8. Indicies of Abundance

```{r indicie_abund, fig.height=8}
# dat_design <- dplyr::bind_rows(
#   read.csv(file = system.file("YFS_10210_estimate_summary.csv",
#                               package = "sdmgamindex" )) %>%
#     dplyr::mutate(common_name = "yellowfin sole"),
#   read.csv(file = system.file("WEP_21740_estimate_summary.csv",
#                               package = "sdmgamindex" ))  %>%
#     dplyr::mutate(common_name = "walleye pollock"),
#   read.csv(file = system.file("RKC_Table_for_SS3.csv",
#                               package = "sdmgamindex" )) %>%
#     dplyr::rename(design_mt = Estimate_metric_tons,
#                   design_se = SD_mt) %>%
#     dplyr::mutate(design_se = (design_se)^2,
#                   design_CV = NA,
#                   VAST_mt = NA,
#                   VAST_se = NA,
#                   VAST_CV = NA,
#                   common_name = "red king crab") %>%
#     dplyr::select(-Unit, -Fleet, -SD_log))

dat_design <- dplyr::bind_rows(
  sdmgamindex::noaa_afsc_biomass_estimates %>%
    dplyr::filter(survey_definition_id == 98 &
                    year %in% YEARS &
                    species_code %in% c(21740, 10210))  %>%
    dplyr::mutate(common_name = dplyr::case_when(
      species_code == 21740 ~ "walleye pollock",
      species_code == 10210 ~ "yellowfin sole")) %>%
    dplyr::select(Year = year, Estimate_metric_tons = biomass_mt, SD_mt = biomass_var, common_name) ,
  read.csv(file = system.file("RKC_Table_for_SS3.csv",
                              package = "sdmgamindex" )) %>%
    dplyr::mutate(common_name = "red king crab") %>%
    dplyr::select(-Unit, -Fleet, -SD_log)) %>%
  dplyr::rename(design_mt = Estimate_metric_tons,
                design_se = SD_mt) %>%
  dplyr::mutate(design_se = (design_se)^2,
                design_CV = NA,
                VAST_mt = NA,
                VAST_se = NA,
                VAST_CV = NA)

dat <- data.frame()
for (i in 1:length(models)){
  temp <- models[[i]]
  dat0 <- data.frame(idx = temp$idx[,1]/1e2, # clearly having an issue with units
                     lo = temp$lo[,1]/1e2, 
                     up = temp$up[,1]/1e2,
                     Year = rownames(temp$idx), 
                     group = names(models)[i],
                     formula = paste0("cpue_kgkm2 ~ ", 
                                      as.character(temp$pModels[[1]]$formula)[[3]]))
  
  dat <- dplyr::bind_rows(dat, dat0) 
}

dat$common_name <- paste0(sapply(X = strsplit(x = dat$group, split = " fm"), `[`, 1))

dat <- dplyr::bind_rows(dat %>% 
                          dplyr::mutate(Year = as.numeric(Year)) %>% 
                          dplyr::select(-group), 
                        dat_design %>% 
                          dplyr::select(design_mt, common_name, Year) %>%
                          dplyr::rename(idx = design_mt) %>%
                          dplyr::mutate(lo = NA, 
                                        up = NA, 
                                        formula = "design")) %>% 
  dplyr::filter(Year %in% YEARS[-1])

dat[dat$Year == 2020, c("idx", "up", "lo")] <- NA

ggplot2::ggplot(data = dat,
                mapping = aes(x = Year, 
                              y = idx, 
                              group = formula, 
                              color = formula)) +
  ggplot2::geom_line(size = 1.5) + 
  ggplot2::geom_point(size = 2)  + 
  ggplot2::geom_ribbon(aes(ymin = lo, ymax = up, fill = formula), 
                       alpha=0.1, 
                       linetype="dashed",
                       color="grey") + 
  ggplot2::ggtitle("Annual Index Model Results") +
  ggplot2::scale_y_continuous(name = "Index", labels = scales::comma) +
  ggplot2::facet_wrap(vars(common_name), scales = "free", ncol = 1) +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = "bottom", 
                 legend.direction = "vertical")
```

## 9. Predict and plot

```{r predict}
dat_pred <- dat_catch_haul %>%
  dplyr::select(Year, sx, sy, Lon, Lat, GEAR_TEMPERATURE, BOTTOM_DEPTH)

dat <- data.frame()
for (i in 1:length(models)) {
  temp <- models[[i]]
  dat0 <- data.frame(idx = 
                       predict.gam(
                         object = temp$pModels[[1]],
                         newdata = dat_pred),  
                     group = names(models)[i], 
                     formula = paste0("cpue_kgkm2 ~ ", 
                                      as.character(temp$pModels[[1]]$formula)[[3]])
  )
  dat00 <- dplyr::bind_cols(dat0, dat_pred) 
  dat <- dplyr::bind_rows(dat, dat00) 
  
}

dat$facet_group <- paste0(sapply(X = strsplit(x = dat$group, split = " fm"), `[`, 1))

for (i in 1:length(unique(dat$facet_group))){
  ggplot2::ggplot(data = dat %>% 
                    dplyr::filter(facet_group == unique(dat$facet_group)[i]), 
                  mapping = aes(x = Lon, 
                                y = Lat, 
                                group = group, 
                                color = idx)) +
    scale_color_viridis_c(option = "D") +
    geom_point()  + 
    ggtitle(paste0("Annual Index Model Results for ", unique(dat$facet_group)[i])) +
    facet_grid(cols = vars(group), 
               rows = vars(Year)) +
    theme_bw()
}
```

```{r}
# sdmgamindex::plot_surveyidx(
#   x = models, 
#   dat = ds, 
#   myids = NULL, 
#   predD = allpd)
```

## 10. Simulations

```{r sim_gam, echo=FALSE, eval=FALSE}

# sims <- fittimes_sims <- list()
# for(i in 1:nrow(comb)){
#   
#   cat("Simulating ",comb$SPECIES[i],"\n", comb$fm_name[i], ": ", comb$fm[i], "\n")
#   
#   temp <- paste0(comb$SPECIES[i], " ", comb$fm_name[i])
#   
#   fittimes[[ temp ]] <-
#     system.time ( sims[[ temp ]] <-
#                     sdmgamindex::get_surveyidx_sim(
#                       model = models[[i]], 
#                       d = ds[[ comb$SPECIES[i] ]]) )
# }
# 
# par(mfrow = c(2, 2)) # Create a 2 x 2 plotting matrix
# for(i in 1:nrow(comb)){
#   plot(sims[[i]]$sim, main = paste0(names(sims)[i], " sims"))
#   plot(sims[[i]]$mu[[1]], main = paste0(names(sims)[i], " mu"))
# }

```

```{r model-sims, eval=FALSE}
REPS <- 4
ests <- list()

for(i in 1:nrow(comb)){
  
  cat("Simulating ",comb$SPECIES[i],"\n", comb$fm_name[i], ": ", comb$fm[i], "\n")
  temp <- paste0(comb$SPECIES[i], " ", comb$fm_name[i])
  
  # for(SPECIES in specLevels){
  ests[[ temp ]] <- list()
  
  ## simulate data
  csim <- sdmgamindex::get_surveyidx_sim(models[[i]], ds[[comb$SPECIES[i]]])
  sims <-lapply(1:REPS,function(j) sdmgamindex::get_surveyidx_sim(
    model = models[[i]],
    d = ds[[comb$SPECIES[i]]], 
    sampleFit = FALSE,
    condSim = csim) )
  
  ## re-estimate
  tmp <- ds[[i]]
  for(ii in 1:REPS) {
    tmp[[2]]$Nage <- matrix(sims[[ii]][[1]][,1],ncol=1)
    colnames(tmp$Nage)<-1
    
    ests[[SPECIES]][[ii]]  <-
      sdmgamindex::get_surveyidx(
        x = tmp,
        ages = 1,
        myids=NULL,
        predD=allpd,
        cutOff=0,
        fam="Tweedie",
        modelP=fm,
        gamma=1,
        control=list(trace=TRUE,maxit=10))
  }
}

sims
ests

png(filename = here::here("inst","simest.png"),
    width=640*pngscal,height=480)
# par(mfrow=c(2,2))
save(sims, ests, file = here::here("inst","vigD_model_fits.Rdata"))
```

```{r model-sims-load, echo = FALSE, eval = FALSE}
load(system.file("vigD_model_sims.Rdata", package = "sdmgamindex") )
sims
ests
```

```{r model-sims-img, echo=FALSE, out.width = '100%', eval = FALSE}

download.file(url = here::here("inst","simest.png"), destfile = img_loc, mode="wb")
knitr::include_graphics(img_loc)
```

```{r sim_gam2, eval=FALSE}
for(i in 1:nrow(comb)){
  sdmgamindex::plot_simulation_list(
    x = ests[[temp]],
    base=models[[temp]],
    main=temp,
    lwd=2)
}
dev.off()
```

# 11. Citations
